{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Workbook Fraud.ipynb",
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "l67QqlNbun5_"
      },
      "source": [
        "!pip install kaggle\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhOY1ZmHhvzP"
      },
      "source": [
        "!kaggle datasets download -d mlg-ulb/creditcardfraud"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykWyf7qChvj9"
      },
      "source": [
        "!unzip creditcardfraud.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABTqhh9Th9WJ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmOtE0J3iK31"
      },
      "source": [
        "df = pd.read_csv(\"/content/creditcard.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxBU5M90Icd3"
      },
      "source": [
        "X=df.drop(columns=[\"Class\"])\n",
        "y=df[\"Class\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fN574P1jIekb"
      },
      "source": [
        "# We standarize\n",
        "from sklearn import preprocessing\n",
        "\n",
        "names=X.columns\n",
        "scaled_df = preprocessing.scale(X)\n",
        "\n",
        "scaled_df = pd.DataFrame(scaled_df,columns=names)\n",
        "scaled_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g42mhFfNIkbj"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(scaled_df, y,\n",
        "                                                    test_size = 0.30, random_state = 0, shuffle = True, stratify = y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4PPTYXOJ8ig"
      },
      "source": [
        "# Smote\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "sm = SMOTE(random_state = 33)\n",
        "X_train_new, y_train_new = sm.fit_sample(X_train, y_train.ravel())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tbm439aSJR8o"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(X_train_new.shape[1], activation = 'relu', input_dim = X_train_new.shape[1]))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dense(64, activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(64, activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(1, activation = 'sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aWLbowZJvJ8"
      },
      "source": [
        "optimizer = keras.optimizers.Adam(lr=0.0001)\n",
        "model.compile(optimizer = optimizer, loss = 'binary_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8490TuXJytI"
      },
      "source": [
        "history = model.fit(x=X_train_new, y=y_train_new, batch_size = 256, epochs=150,\n",
        "          validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDkinrSQKLZR"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "evaluation_metrics=pd.DataFrame(model.history.history)\n",
        "evaluation_metrics.plot(figsize=(10,5))\n",
        "plt.title(\"Loss for both Training and Validation\", size = 20)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ij7lRZOZPlKx"
      },
      "source": [
        "y_pred = model.predict_classes(X_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORLemrH_R0zG"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "\n",
        "cm_nn=confusion_matrix(y_test, y_pred)\n",
        "cm_nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QglGx5J6R3o8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}