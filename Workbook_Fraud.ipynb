{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Workbook Fraud.ipynb",
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wX0f47k5cW6V"
      },
      "source": [
        "# Setting up Data and Google Colab import "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l67QqlNbun5_"
      },
      "source": [
        "!pip install kaggle\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhOY1ZmHhvzP"
      },
      "source": [
        "!kaggle datasets download -d mlg-ulb/creditcardfraud"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykWyf7qChvj9"
      },
      "source": [
        "!unzip creditcardfraud.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQYitBJLcsW0"
      },
      "source": [
        "# Setting up Data and doing some preliminary exploration.\n",
        "Very basic since we have generated the report previously. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABTqhh9Th9WJ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmOtE0J3iK31"
      },
      "source": [
        "df = pd.read_csv(\"/content/creditcard.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-wjVuDJiOGj"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIH1Jq6JqweA"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4P7CEUzAqw8U"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyhevTMkq1Kd"
      },
      "source": [
        "print (\"Fraudulent\")\n",
        "print (df.Amount[df.Class == 1].describe())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMmwWWSErfnX"
      },
      "source": [
        "print(\"Normal\")\n",
        "print(df.Amount[df.Class == 0].describe())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkwtZwDws_zr"
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline \n",
        "\n",
        "df['Hour'] = df['Time'].apply(lambda x: np.floor(x / 3600))\n",
        "\n",
        "tmp = df.groupby(['Hour', 'Class'])['Amount'].aggregate(['min', 'max', 'count', 'sum', 'mean', 'median', 'var']).reset_index()\n",
        "df = pd.DataFrame(tmp)\n",
        "df.columns = ['Hour', 'Class', 'Min', 'Max', 'Transactions', 'Sum', 'Mean', 'Median', 'Var']\n",
        "df.head()\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(18,6))\n",
        "s = sns.lineplot(ax = ax1, x=\"Hour\", y=\"Sum\", data=df.loc[df.Class==0])\n",
        "s = sns.lineplot(ax = ax2, x=\"Hour\", y=\"Sum\", data=df.loc[df.Class==1], color=\"red\")\n",
        "plt.suptitle(\"Total Amount\")\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVuH1IhRddmQ"
      },
      "source": [
        "#Â Preparing to model: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCSwkBGrs_uh"
      },
      "source": [
        "target = 'Class'\n",
        "predictors = ['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
        "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19',\n",
        "       'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28',\n",
        "       'Amount']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LqttdlilG8A"
      },
      "source": [
        "df = pd.read_csv(\"/content/creditcard.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4R-o_nedj7M"
      },
      "source": [
        " ## Creating the data frames for training and validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpZO45IUFHhQ"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=0, shuffle=True )\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pxbb4uiTWd0e"
      },
      "source": [
        "train_df, valid_df = train_test_split(train_df, test_size=0.2, random_state=0, shuffle=True )\n",
        "\n",
        "valid_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnRrkhcTdtri"
      },
      "source": [
        "# Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbgM2lu9Oacd"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "clf = RandomForestClassifier()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lm5uIrylPyGU"
      },
      "source": [
        "clf.fit(df[predictors], df[target].values)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJ0Pfq6OQWA_"
      },
      "source": [
        "preds = clf.predict(valid_df[predictors])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87gW4dn6UA9k"
      },
      "source": [
        "tmp = pd.DataFrame({'Feature': predictors, 'Feature importance': clf.feature_importances_})\n",
        "tmp = tmp.sort_values(by='Feature importance',ascending=False)\n",
        "plt.figure(figsize = (10,5))\n",
        "plt.title('Features importance',fontsize=14)\n",
        "s = sns.barplot(x='Feature',y='Feature importance',data=tmp)\n",
        "s.set_xticklabels(s.get_xticklabels(),rotation=90)\n",
        "plt.show()   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMSvXtjjX_1L"
      },
      "source": [
        "cm = pd.crosstab(valid_df[target].values, preds, rownames=['Actual'], colnames=['Predicted'])\n",
        "fig, (ax1) = plt.subplots(ncols=1, figsize=(5,5))\n",
        "sns.heatmap(cm, \n",
        "            xticklabels=['Not Fraud', 'Fraud'],\n",
        "            yticklabels=['Not Fraud', 'Fraud'],\n",
        "            annot=True,ax=ax1,\n",
        "            linewidths=.2,linecolor=\"Darkblue\", cmap=\"Blues\")\n",
        "plt.title('Confusion Matrix', fontsize=14)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lh0S0_crfUTH"
      },
      "source": [
        "# Trying XGboost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p49hvxIUYDEp"
      },
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "# Prepare the train and valid datasets\n",
        "dtrain = xgb.DMatrix(train_df[predictors], train_df[target].values)\n",
        "dvalid = xgb.DMatrix(valid_df[predictors], valid_df[target].values)\n",
        "dtest = xgb.DMatrix(test_df[predictors], test_df[target].values)\n",
        "\n",
        "#What to monitor (in this case, **train** and **valid**)\n",
        "watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n",
        "\n",
        "# Xgboost parameters\n",
        "params = {}\n",
        "params['objective'] = 'binary:logistic'\n",
        "params['eta'] = 0.039\n",
        "params['silent'] = True\n",
        "params['max_depth'] = 2\n",
        "params['subsample'] = 0.8\n",
        "params['colsample_bytree'] = 0.9\n",
        "params['eval_metric'] = 'auc'\n",
        "params['random_state'] = 2018\n",
        "\n",
        "model = xgb.train(params, \n",
        "                dtrain, \n",
        "                1000, \n",
        "                watchlist, \n",
        "                early_stopping_rounds=50, \n",
        "                maximize=True, \n",
        "                verbose_eval=50)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q52QSW-x2UY_"
      },
      "source": [
        "fig, (ax) = plt.subplots(ncols=1, figsize=(8,5))\n",
        "xgb.plot_importance(model, height=0.8, title=\"Features importance (XGBoost)\", ax=ax, color=\"green\") \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jI2iPr782Wd3"
      },
      "source": [
        "preds = model.predict(dtest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHkI4KHX2WUk"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "roc_auc_score(test_df[target].values, preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ol_dn9Dj2ewu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}